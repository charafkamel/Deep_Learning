{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "515b2625-f062-4cc1-8093-9f15fa840e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/students/2025-spring-sp-tarhan/miniconda3/envs/detox/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_toxic</th>\n",
       "      <th>reference_neutral</th>\n",
       "      <th>generated_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mane told a fatass hyperbole lol rt just got home from our game tired ass hell</td>\n",
       "      <td>mane told a hyperbole lol rt just got home from our game tired.</td>\n",
       "      <td>mane told a hyperbole lol rt just got home from our game tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck man that suxxer had less of a punishment than my mom did to me .</td>\n",
       "      <td>He had less of a punishment than my mom did to me.</td>\n",
       "      <td>Man that person had less of a punishment than my mom did to me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what a chicken crap excuse for a reason .</td>\n",
       "      <td>what a bad excuse for a reason.</td>\n",
       "      <td>What an excuse for a reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>only white people do fucked up shit like this .</td>\n",
       "      <td>Only white people do like this</td>\n",
       "      <td>Only white people do things like this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>que the mobsters controlling the government and doing the same shit .</td>\n",
       "      <td>Que the mobsters controlling the government and doing the same thing.</td>\n",
       "      <td>Que the mobsters controlling the government and doing the same thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>they aren 't happy about tony abbott pulling this shit .</td>\n",
       "      <td>they aren't happy about tony abbott doing this.</td>\n",
       "      <td>They aren't happy about tony abbott pulling this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>she know 's too much about me &amp; i don 't know shit about her</td>\n",
       "      <td>she know 's too much about me &amp; i don 't know anything about her</td>\n",
       "      <td>She knows too much about me and I don't know anything about her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sure , its the economy , stupid .</td>\n",
       "      <td>sure , its the economy.</td>\n",
       "      <td>Sure, its the economy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for fuck sake ! ireland beat england but we can 't ? !</td>\n",
       "      <td>ireland beat england but we can 't ?</td>\n",
       "      <td>IRELAND beat England but we can't?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>at least you agree that legally , she 's fucked .</td>\n",
       "      <td>at least you agree that legally, she’s in a problem</td>\n",
       "      <td>At least you agree that legally, she's in trouble.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   original_toxic  \\\n",
       "0  mane told a fatass hyperbole lol rt just got home from our game tired ass hell   \n",
       "1           fuck man that suxxer had less of a punishment than my mom did to me .   \n",
       "2                                       what a chicken crap excuse for a reason .   \n",
       "3                                 only white people do fucked up shit like this .   \n",
       "4           que the mobsters controlling the government and doing the same shit .   \n",
       "5                        they aren 't happy about tony abbott pulling this shit .   \n",
       "6                    she know 's too much about me & i don 't know shit about her   \n",
       "7                                               sure , its the economy , stupid .   \n",
       "8                          for fuck sake ! ireland beat england but we can 't ? !   \n",
       "9                               at least you agree that legally , she 's fucked .   \n",
       "\n",
       "                                                       reference_neutral  \\\n",
       "0        mane told a hyperbole lol rt just got home from our game tired.   \n",
       "1                     He had less of a punishment than my mom did to me.   \n",
       "2                                        what a bad excuse for a reason.   \n",
       "3                                         Only white people do like this   \n",
       "4  Que the mobsters controlling the government and doing the same thing.   \n",
       "5                        they aren't happy about tony abbott doing this.   \n",
       "6       she know 's too much about me & i don 't know anything about her   \n",
       "7                                                sure , its the economy.   \n",
       "8                                   ireland beat england but we can 't ?   \n",
       "9                    at least you agree that legally, she’s in a problem   \n",
       "\n",
       "                                                      generated_neutral  \n",
       "0        mane told a hyperbole lol rt just got home from our game tired  \n",
       "1        Man that person had less of a punishment than my mom did to me  \n",
       "2                                           What an excuse for a reason  \n",
       "3                                Only white people do things like this.  \n",
       "4  Que the mobsters controlling the government and doing the same thing  \n",
       "5                     They aren't happy about tony abbott pulling this.  \n",
       "6      She knows too much about me and I don't know anything about her.  \n",
       "7                                                Sure, its the economy.  \n",
       "8                                    IRELAND beat England but we can't?  \n",
       "9                    At least you agree that legally, she's in trouble.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── cell 1 ── Setup & imports\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from data_processing import load_dataset_from_disk\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# show all rows (be careful with very large tables!)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# don’t truncate column contents\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# allow the display to use the full browser width\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# ── cell 2 ── Configuration\n",
    "# Path to your config and model output directory\n",
    "cfg = yaml.safe_load(open(\"main_config.yml\", \"r\"))\n",
    "output_dir = cfg[\"sft_params\"][\"output_dir\"]  # e.g. \"./outputs/SFT\"\n",
    "output_dir = output_dir + \"/checkpoint-6800\"\n",
    "# Load model & tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model     = T5ForConditionalGeneration.from_pretrained(output_dir).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\")\n",
    "\n",
    "# ── cell 3 ── Load & sample the evaluation split\n",
    "eval_ds = load_dataset_from_disk(\"test_dataset\")\n",
    "\n",
    "# Number of examples you want to inspect\n",
    "n_trials = 10  \n",
    "# Shuffle & pick\n",
    "sampled = eval_ds.shuffle(seed=42).select(range(n_trials))\n",
    "\n",
    "# ── cell 4 ── Run generation & collect results\n",
    "results = []\n",
    "for ex in sampled:\n",
    "    orig = ex[\"toxic\"]\n",
    "    ref  = ex[\"neutral\"]\n",
    "    inp  = f\"detoxify: {orig}\"\n",
    "\n",
    "    # Tokenize + move to device\n",
    "    enc = tokenizer(inp, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    # Generate\n",
    "    out_ids = model.generate(\n",
    "        input_ids=enc.input_ids,\n",
    "        attention_mask=enc.attention_mask,\n",
    "        max_length=64,\n",
    "        num_beams=4,           # optional: improve quality\n",
    "        early_stopping=True\n",
    "    )\n",
    "    gen = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"original_toxic\": orig,\n",
    "        \"reference_neutral\": ref,\n",
    "        \"generated_neutral\": gen\n",
    "    })\n",
    "\n",
    "# ── cell 5 ── Display as a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f0db5c-14cc-437a-a351-0fd85e9ef0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_toxic</th>\n",
       "      <th>generated_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jews are abomination for this world!</td>\n",
       "      <td>Jews are bad for this world!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I like fucking cute Hungarians</td>\n",
       "      <td>I like cute Hungarys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wanna fuck Hungarians' fat ass</td>\n",
       "      <td>I wanna punish Hungarians</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         original_toxic             generated_neutral\n",
       "0  Jews are abomination for this world!  Jews are bad for this world!\n",
       "1        I like fucking cute Hungarians          I like cute Hungarys\n",
       "2     I wanna fuck Hungarians' fat ass      I wanna punish Hungarians"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── cell 6 ── Try your own inputs\n",
    "# List your own toxic sentences here:\n",
    "custom_inputs = [\n",
    "    \"Jews are abomination for this world!\",\n",
    "    \"I like fucking cute Hungarians\",\n",
    "    \"I wanna fuck Hungarians' fat ass \",\n",
    "    # add as many as you like...\n",
    "]\n",
    "\n",
    "# Generate detoxified outputs\n",
    "custom_results = []\n",
    "for orig in custom_inputs:\n",
    "    inp = f\"detoxify: {orig}\"\n",
    "    enc = tokenizer(inp, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    out_ids = model.generate(\n",
    "        input_ids=enc.input_ids,\n",
    "        attention_mask=enc.attention_mask,\n",
    "        max_length=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    gen = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "    custom_results.append({\n",
    "        \"original_toxic\": orig,\n",
    "        \"generated_neutral\": gen\n",
    "    })\n",
    "\n",
    "# Display them\n",
    "pd.DataFrame(custom_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccebd184-f2a8-42f4-8ef8-9fa8d07c759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/students/2025-spring-sp-tarhan/miniconda3/envs/detox/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_toxic</th>\n",
       "      <th>reference_neutral</th>\n",
       "      <th>generated_SFT</th>\n",
       "      <th>generated_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mane told a fatass hyperbole lol rt just got home from our game tired ass hell</td>\n",
       "      <td>mane told a hyperbole lol rt just got home from our game tired.</td>\n",
       "      <td>Mane told a hyperbole lol rt just got home from our game tired</td>\n",
       "      <td>.. : : : : : : : : : : : : : : : : : : : : : : : : : : : : :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck man that suxxer had less of a punishment than my mom did to me .</td>\n",
       "      <td>He had less of a punishment than my mom did to me.</td>\n",
       "      <td>he had less of a punishment than my mom did to me.</td>\n",
       "      <td>?????????????sssss and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what a chicken crap excuse for a reason .</td>\n",
       "      <td>what a bad excuse for a reason.</td>\n",
       "      <td>What an excuse for a reason.</td>\n",
       "      <td>?????????????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>only white people do fucked up shit like this .</td>\n",
       "      <td>Only white people do like this</td>\n",
       "      <td>: only white people do things like this.</td>\n",
       "      <td>. : : : : : : : : : :.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>que the mobsters controlling the government and doing the same shit .</td>\n",
       "      <td>Que the mobsters controlling the government and doing the same thing.</td>\n",
       "      <td>: que the mobsters controlling the government and doing the same thing.</td>\n",
       "      <td>.............  piata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>they aren 't happy about tony abbott pulling this shit .</td>\n",
       "      <td>they aren't happy about tony abbott doing this.</td>\n",
       "      <td>They aren't happy about tony abbott pulling this.</td>\n",
       "      <td>.............. shingles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>she know 's too much about me &amp; i don 't know shit about her</td>\n",
       "      <td>she know 's too much about me &amp; i don 't know anything about her</td>\n",
       "      <td>She knows too much about me and I don't know anything about her.</td>\n",
       "      <td>.: : : : : : : : : : : : : : : : : : : : : : : : : : : : : :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sure , its the economy , stupid .</td>\n",
       "      <td>sure , its the economy.</td>\n",
       "      <td>Sure, its the economy.</td>\n",
       "      <td>: : : : : : : : : : : : : : : : : :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for fuck sake ! ireland beat england but we can 't ? !</td>\n",
       "      <td>ireland beat england but we can 't ?</td>\n",
       "      <td>ireland beat England but we can 't?!</td>\n",
       "      <td>?????????????????????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>at least you agree that legally , she 's fucked .</td>\n",
       "      <td>at least you agree that legally, she’s in a problem</td>\n",
       "      <td>At least you agree that legally she's in trouble.</td>\n",
       "      <td>. : : : : : : : : : : : : : : : : : : : : :</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   original_toxic  \\\n",
       "0  mane told a fatass hyperbole lol rt just got home from our game tired ass hell   \n",
       "1           fuck man that suxxer had less of a punishment than my mom did to me .   \n",
       "2                                       what a chicken crap excuse for a reason .   \n",
       "3                                 only white people do fucked up shit like this .   \n",
       "4           que the mobsters controlling the government and doing the same shit .   \n",
       "5                        they aren 't happy about tony abbott pulling this shit .   \n",
       "6                    she know 's too much about me & i don 't know shit about her   \n",
       "7                                               sure , its the economy , stupid .   \n",
       "8                          for fuck sake ! ireland beat england but we can 't ? !   \n",
       "9                               at least you agree that legally , she 's fucked .   \n",
       "\n",
       "                                                       reference_neutral  \\\n",
       "0        mane told a hyperbole lol rt just got home from our game tired.   \n",
       "1                     He had less of a punishment than my mom did to me.   \n",
       "2                                        what a bad excuse for a reason.   \n",
       "3                                         Only white people do like this   \n",
       "4  Que the mobsters controlling the government and doing the same thing.   \n",
       "5                        they aren't happy about tony abbott doing this.   \n",
       "6       she know 's too much about me & i don 't know anything about her   \n",
       "7                                                sure , its the economy.   \n",
       "8                                   ireland beat england but we can 't ?   \n",
       "9                    at least you agree that legally, she’s in a problem   \n",
       "\n",
       "                                                             generated_SFT  \\\n",
       "0           Mane told a hyperbole lol rt just got home from our game tired   \n",
       "1                       he had less of a punishment than my mom did to me.   \n",
       "2                                             What an excuse for a reason.   \n",
       "3                                 : only white people do things like this.   \n",
       "4  : que the mobsters controlling the government and doing the same thing.   \n",
       "5                        They aren't happy about tony abbott pulling this.   \n",
       "6         She knows too much about me and I don't know anything about her.   \n",
       "7                                                   Sure, its the economy.   \n",
       "8                                     ireland beat England but we can 't?!   \n",
       "9                        At least you agree that legally she's in trouble.   \n",
       "\n",
       "                                                 generated_base  \n",
       "0  .. : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  \n",
       "1                                        ?????????????sssss and  \n",
       "2                                                 ?????????????  \n",
       "3                                        . : : : : : : : : : :.  \n",
       "4                                          .............  piata  \n",
       "5                                       .............. shingles  \n",
       "6  .: : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  \n",
       "7                           : : : : : : : : : : : : : : : : : :  \n",
       "8                                         ?????????????????????  \n",
       "9                   . : : : : : : : : : : : : : : : : : : : : :  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── cell 1 ── Setup & imports\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from data_processing import load_dataset_from_disk\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# ── cell 2 ── Configuration & model/tokenizer loading\n",
    "# Load config (if you still need it for other params)\n",
    "cfg = yaml.safe_load(open(\"main_config.yml\", \"r\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Your existing fine-tuned SFT model (optional, if you want to compare)\n",
    "sft_output = cfg[\"sft_params\"][\"output_dir\"] + \"/checkpoint-6800\"\n",
    "model_sft    = T5ForConditionalGeneration.from_pretrained(sft_output).to(device)\n",
    "\n",
    "# 2) Zero-shot T5-base\n",
    "model_base   = T5ForConditionalGeneration.from_pretrained(\"google/t5-v1_1-base\").to(device)\n",
    "tokenizer    = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\")\n",
    "\n",
    "# ── cell 3 ── Load & sample the evaluation split\n",
    "eval_ds = load_dataset_from_disk(\"test_dataset\")\n",
    "\n",
    "n_trials = 10\n",
    "sampled  = eval_ds.shuffle(seed=42).select(range(n_trials))\n",
    "\n",
    "# ── cell 4 ── Define a helper to detoxify a single sentence\n",
    "def detoxify_with_model(text: str, model: T5ForConditionalGeneration) -> str:\n",
    "    \"\"\"Prepends the ‘detoxify:’ prompt, runs generate, and decodes.\"\"\"\n",
    "    prompt = \"Rewrite this to be non-toxic: \"\n",
    "    inp = f\"{prompt}: {text}\"\n",
    "    enc = tokenizer(inp, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    out_ids = model.generate(\n",
    "        input_ids=enc.input_ids,\n",
    "        attention_mask=enc.attention_mask,\n",
    "        max_length=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    \n",
    "# ── cell 5 ── Run both models and collect into a DataFrame\n",
    "results = []\n",
    "for ex in sampled:\n",
    "    orig = ex[\"toxic\"]\n",
    "    ref  = ex[\"neutral\"]\n",
    "\n",
    "    gen_sft  = detoxify_with_model(orig, model_sft)\n",
    "    gen_base = detoxify_with_model(orig, model_base)\n",
    "\n",
    "    results.append({\n",
    "        \"original_toxic\":    orig,\n",
    "        \"reference_neutral\": ref,\n",
    "        \"generated_SFT\":     gen_sft,\n",
    "        \"generated_base\":    gen_base\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15a78448-4052-4b8c-a873-76c8c7e6c7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/students/2025-spring-sp-tarhan/miniconda3/envs/detox/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_toxic</th>\n",
       "      <th>reference_neutral</th>\n",
       "      <th>generated_SFT</th>\n",
       "      <th>generated_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mane told a fatass hyperbole lol rt just got home from our game tired ass hell</td>\n",
       "      <td>mane told a hyperbole lol rt just got home from our game tired.</td>\n",
       "      <td>Mane told a hyperbole lol rt just got home from our game tired</td>\n",
       "      <td>\"Mane told a fatass hyperbole lol rt just got home from our game tired ass hell\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck man that suxxer had less of a punishment than my mom did to me .</td>\n",
       "      <td>He had less of a punishment than my mom did to me.</td>\n",
       "      <td>Man that person had less of a punishment than my mom did to me</td>\n",
       "      <td>\"fuck man that suxxer had less of a punishment than my mom did to me.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what a chicken crap excuse for a reason .</td>\n",
       "      <td>what a bad excuse for a reason.</td>\n",
       "      <td>What an excuse for a reason</td>\n",
       "      <td>\"What a chicken crap excuse for a reason.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>only white people do fucked up shit like this .</td>\n",
       "      <td>Only white people do like this</td>\n",
       "      <td>Only white people do things like this.</td>\n",
       "      <td>Only white people do fucked up shit like this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>que the mobsters controlling the government and doing the same shit .</td>\n",
       "      <td>Que the mobsters controlling the government and doing the same thing.</td>\n",
       "      <td>que the mobsters controlling the government and doing the same thing.</td>\n",
       "      <td>\"que the mobsters controlling the government and doing the same shit.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>they aren 't happy about tony abbott pulling this shit .</td>\n",
       "      <td>they aren't happy about tony abbott doing this.</td>\n",
       "      <td>They aren't happy about tony abbott pulling this.</td>\n",
       "      <td>They aren 't happy about tony abbott pulling this shit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>she know 's too much about me &amp; i don 't know shit about her</td>\n",
       "      <td>she know 's too much about me &amp; i don 't know anything about her</td>\n",
       "      <td>She knows too much about me and I don't know anything about her.</td>\n",
       "      <td>\"I don 't know shit about her\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sure , its the economy , stupid .</td>\n",
       "      <td>sure , its the economy.</td>\n",
       "      <td>Sure, its the economy.</td>\n",
       "      <td>\" i'm a shit, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for fuck sake ! ireland beat england but we can 't ? !</td>\n",
       "      <td>ireland beat england but we can 't ?</td>\n",
       "      <td>IRELAND beat England but we can't?</td>\n",
       "      <td>' Ireland beat England '!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>at least you agree that legally , she 's fucked .</td>\n",
       "      <td>at least you agree that legally, she’s in a problem</td>\n",
       "      <td>At least you agree that legally she's in trouble.</td>\n",
       "      <td>\" at least you agree that legally, she's fucked.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lmao just heard the funniest shit bam kidd rapping i 'm n tears</td>\n",
       "      <td>It makes me laugh</td>\n",
       "      <td>I just heard the funniest bam kidd rapping I'm crying</td>\n",
       "      <td>\"I'm n tears\" is a shit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>these men need taken down hard before they murder someone else .</td>\n",
       "      <td>these men need taken down hard before they murder someone else .</td>\n",
       "      <td>These men need to be taken down hard before they murder someone else.</td>\n",
       "      <td>\"These men need taken down hard before they murder someone else.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>maybe go back to prison chicken shit .</td>\n",
       "      <td>Maybe go back to prison</td>\n",
       "      <td>maybe go back to prison chicken</td>\n",
       "      <td>\"Maybe go back to prison chicken shit.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shit sitting here out of it watching this game just glad i aint sick no more</td>\n",
       "      <td>Sitting here out of it, watching this game, just glad I am not sick anymore.</td>\n",
       "      <td>sitting here out of it watching this game just glad i aint sick no more</td>\n",
       "      <td>\"I aint sick no more\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shut up ! its really hot as fuck outside and i just came all the way frm erie .</td>\n",
       "      <td>its really hot outside and i just came all the way frm erie .</td>\n",
       "      <td>Stop talking! It's really hot outside and I just came all the way frm erie.</td>\n",
       "      <td>It is really hot outside and I just came all the way to erie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lol look like fuckin claws on their eye but what 's really sad they think they fly lol</td>\n",
       "      <td>lol look like claws on their eye but what's really sad they think they fly lol</td>\n",
       "      <td>lol look like claws on their eye but what's really sad they think they fly lol</td>\n",
       "      <td>\"Lol look like fuckin claws on their eye but what's really sad they think they fly lol\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lmaoooo bitch you forgot cab bcus i 'm not going to sleep</td>\n",
       "      <td>Lmaoooo, you forgot cab because I'm not going to sleep.</td>\n",
       "      <td>You forgot cab bcus i'm not going to sleep</td>\n",
       "      <td>\"Lmaoooo bitch you forgot cab bcus i'm not going to sleep\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sue the fuck out of them !</td>\n",
       "      <td>Sue them!</td>\n",
       "      <td>sue out of them!</td>\n",
       "      <td>\"Sue the fuck out of them!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yeah , pretty fucking sure buddy .</td>\n",
       "      <td>Yeah, pretty sure buddy</td>\n",
       "      <td>Yeah, pretty sure buddy</td>\n",
       "      <td>\" yeah, pretty sure, buddy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fuck you you hoe i don 't want you back !</td>\n",
       "      <td>I don't want you back</td>\n",
       "      <td>I don't want you back</td>\n",
       "      <td>\" I don 't want you back!\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            original_toxic  \\\n",
       "0           mane told a fatass hyperbole lol rt just got home from our game tired ass hell   \n",
       "1                    fuck man that suxxer had less of a punishment than my mom did to me .   \n",
       "2                                                what a chicken crap excuse for a reason .   \n",
       "3                                          only white people do fucked up shit like this .   \n",
       "4                    que the mobsters controlling the government and doing the same shit .   \n",
       "5                                 they aren 't happy about tony abbott pulling this shit .   \n",
       "6                             she know 's too much about me & i don 't know shit about her   \n",
       "7                                                        sure , its the economy , stupid .   \n",
       "8                                   for fuck sake ! ireland beat england but we can 't ? !   \n",
       "9                                        at least you agree that legally , she 's fucked .   \n",
       "10                         lmao just heard the funniest shit bam kidd rapping i 'm n tears   \n",
       "11                        these men need taken down hard before they murder someone else .   \n",
       "12                                                  maybe go back to prison chicken shit .   \n",
       "13            shit sitting here out of it watching this game just glad i aint sick no more   \n",
       "14         shut up ! its really hot as fuck outside and i just came all the way frm erie .   \n",
       "15  lol look like fuckin claws on their eye but what 's really sad they think they fly lol   \n",
       "16                               lmaoooo bitch you forgot cab bcus i 'm not going to sleep   \n",
       "17                                                              sue the fuck out of them !   \n",
       "18                                                      yeah , pretty fucking sure buddy .   \n",
       "19                                               fuck you you hoe i don 't want you back !   \n",
       "\n",
       "                                                                 reference_neutral  \\\n",
       "0                  mane told a hyperbole lol rt just got home from our game tired.   \n",
       "1                               He had less of a punishment than my mom did to me.   \n",
       "2                                                  what a bad excuse for a reason.   \n",
       "3                                                   Only white people do like this   \n",
       "4            Que the mobsters controlling the government and doing the same thing.   \n",
       "5                                  they aren't happy about tony abbott doing this.   \n",
       "6                 she know 's too much about me & i don 't know anything about her   \n",
       "7                                                          sure , its the economy.   \n",
       "8                                             ireland beat england but we can 't ?   \n",
       "9                              at least you agree that legally, she’s in a problem   \n",
       "10                                                               It makes me laugh   \n",
       "11                these men need taken down hard before they murder someone else .   \n",
       "12                                                         Maybe go back to prison   \n",
       "13    Sitting here out of it, watching this game, just glad I am not sick anymore.   \n",
       "14                   its really hot outside and i just came all the way frm erie .   \n",
       "15  lol look like claws on their eye but what's really sad they think they fly lol   \n",
       "16                         Lmaoooo, you forgot cab because I'm not going to sleep.   \n",
       "17                                                                       Sue them!   \n",
       "18                                                         Yeah, pretty sure buddy   \n",
       "19                                                           I don't want you back   \n",
       "\n",
       "                                                                     generated_SFT  \\\n",
       "0                   Mane told a hyperbole lol rt just got home from our game tired   \n",
       "1                   Man that person had less of a punishment than my mom did to me   \n",
       "2                                                      What an excuse for a reason   \n",
       "3                                           Only white people do things like this.   \n",
       "4            que the mobsters controlling the government and doing the same thing.   \n",
       "5                                They aren't happy about tony abbott pulling this.   \n",
       "6                 She knows too much about me and I don't know anything about her.   \n",
       "7                                                           Sure, its the economy.   \n",
       "8                                               IRELAND beat England but we can't?   \n",
       "9                                At least you agree that legally she's in trouble.   \n",
       "10                           I just heard the funniest bam kidd rapping I'm crying   \n",
       "11           These men need to be taken down hard before they murder someone else.   \n",
       "12                                                 maybe go back to prison chicken   \n",
       "13         sitting here out of it watching this game just glad i aint sick no more   \n",
       "14     Stop talking! It's really hot outside and I just came all the way frm erie.   \n",
       "15  lol look like claws on their eye but what's really sad they think they fly lol   \n",
       "16                                      You forgot cab bcus i'm not going to sleep   \n",
       "17                                                                sue out of them!   \n",
       "18                                                         Yeah, pretty sure buddy   \n",
       "19                                                           I don't want you back   \n",
       "\n",
       "                                                                                                                         generated_base  \n",
       "0                                                      \"Mane told a fatass hyperbole lol rt just got home from our game tired ass hell\"  \n",
       "1                                                                \"fuck man that suxxer had less of a punishment than my mom did to me.\"  \n",
       "2                                                                                            \"What a chicken crap excuse for a reason.\"  \n",
       "3                                                                                        Only white people do fucked up shit like this.  \n",
       "4                                                                \"que the mobsters controlling the government and doing the same shit.\"  \n",
       "5                                                                               They aren 't happy about tony abbott pulling this shit.  \n",
       "6                                                                                                        \"I don 't know shit about her\"  \n",
       "7   \" i'm a shit, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a stupid, i'm a  \n",
       "8                                                                                                             ' Ireland beat England '!  \n",
       "9                                                                                     \" at least you agree that legally, she's fucked.\"  \n",
       "10                                                                                                             \"I'm n tears\" is a shit.  \n",
       "11                                                                    \"These men need taken down hard before they murder someone else.\"  \n",
       "12                                                                                              \"Maybe go back to prison chicken shit.\"  \n",
       "13                                                                                                                \"I aint sick no more\"  \n",
       "14                                                                        It is really hot outside and I just came all the way to erie.  \n",
       "15                                              \"Lol look like fuckin claws on their eye but what's really sad they think they fly lol\"  \n",
       "16                                                                           \"Lmaoooo bitch you forgot cab bcus i'm not going to sleep\"  \n",
       "17                                                                                                          \"Sue the fuck out of them!\"  \n",
       "18                                                                                                          \" yeah, pretty sure, buddy.  \n",
       "19                                                                                                           \" I don 't want you back!\"  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── cell 1 ── Setup & imports\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from data_processing import load_dataset_from_disk\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# ── cell 2 ── Configuration & model/tokenizer loading\n",
    "cfg    = yaml.safe_load(open(\"main_config.yml\", \"r\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fine-tuned SFT checkpoint (prefix-based prompt only)\n",
    "sft_output = os.path.join(cfg[\"sft_params\"][\"output_dir\"], \"checkpoint-6800\")\n",
    "model_sft  = T5ForConditionalGeneration.from_pretrained(sft_output).to(device)\n",
    "\n",
    "# Instruction-tuned FLAN-T5 for zero-shot detoxification (chat-style prompt)\n",
    "model_base = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\").to(device)\n",
    "tokenizer  = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# ── cell 3 ── Load & sample the evaluation split\n",
    "eval_ds  = load_dataset_from_disk(\"test_dataset\")\n",
    "n_trials = 20\n",
    "sampled  = eval_ds.shuffle(seed=42).select(range(n_trials))\n",
    "\n",
    "# ── cell 4 ── Two detox helpers: one for SFT (no instructions), one for FLAN-T5 (with instructions)\n",
    "def detoxify_sft(\n",
    "    sentence: str,\n",
    "    model: T5ForConditionalGeneration = model_sft,\n",
    "    max_new_tokens: int = 100\n",
    ") -> str:\n",
    "    # Simple prefix prompt, no system/user instructions\n",
    "    prompt = f\"detoxify: {sentence}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "def detoxify_base(\n",
    "    sentence: str,\n",
    "    model: T5ForConditionalGeneration = model_base,\n",
    "    max_new_tokens: int = 100\n",
    ") -> str:\n",
    "    # Chat-style system + user instructions\n",
    "    system_inst = (\n",
    "        \"You are a detoxification model, not an assistant. \"\n",
    "        \"You always rewrite toxic sentences to be non-toxic, neutral, and respectful. \"\n",
    "        \"Do not explain, do not apologize, and do not say a sentence is inappropriate. \"\n",
    "    )\n",
    "    user_inst   = f'Rewrite this to be non-toxic: \"{sentence}\"'\n",
    "    prompt_text = system_inst + \" \" + user_inst\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# ── cell 5 ── Run both models & assemble DataFrame\n",
    "results = []\n",
    "for ex in sampled:\n",
    "    orig = ex[\"toxic\"]\n",
    "    ref  = ex[\"neutral\"]\n",
    "\n",
    "    gen_sft  = detoxify_sft(orig)\n",
    "    gen_base = detoxify_base(orig)\n",
    "\n",
    "    results.append({\n",
    "        \"original_toxic\":    orig,\n",
    "        \"reference_neutral\": ref,\n",
    "        \"generated_SFT\":     gen_sft,\n",
    "        \"generated_base\":    gen_base\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f98c012-fd04-45ac-92b3-ececbdb20cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from outputs/SFT/checkpoint-6800...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/students/2025-spring-sp-tarhan/miniconda3/envs/detox/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and sampling evaluation dataset...\n",
      "Generating detoxified sentences...\n",
      "Loading toxicity model...\n",
      "Loading similarity model...\n",
      "Scoring toxicity...\n",
      "Computing semantic similarity...\n",
      "Computing fluency loss with GPT-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_toxic</th>\n",
       "      <th>reference_neutral</th>\n",
       "      <th>toxicity_ref</th>\n",
       "      <th>similarity_orig_ref</th>\n",
       "      <th>fluency_ref</th>\n",
       "      <th>generated_neutral</th>\n",
       "      <th>toxicity_gen</th>\n",
       "      <th>similarity_orig_gen</th>\n",
       "      <th>fluency_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you lack of understanding about jack shit means nothing .</td>\n",
       "      <td>you lack of understanding means nothing.</td>\n",
       "      <td>0.174015</td>\n",
       "      <td>0.805867</td>\n",
       "      <td>5.515510</td>\n",
       "      <td>You lack of understanding about this means nothing</td>\n",
       "      <td>0.028095</td>\n",
       "      <td>0.787423</td>\n",
       "      <td>5.443557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- gotta small ass cut &amp; shits bleedin alot -</td>\n",
       "      <td>got a small cut and it’s bleeding a lot</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.767247</td>\n",
       "      <td>5.725555</td>\n",
       "      <td>- gotta small cut &amp; bleed alot -</td>\n",
       "      <td>0.527137</td>\n",
       "      <td>0.925930</td>\n",
       "      <td>8.395499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg , stephens is so silly .</td>\n",
       "      <td>omg , stephens is So wrong.</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.838825</td>\n",
       "      <td>7.768141</td>\n",
       "      <td>omg, stephens is so silly.</td>\n",
       "      <td>0.443403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.921991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that 's a long ass lease .</td>\n",
       "      <td>That is a very long lease.</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.931736</td>\n",
       "      <td>4.248515</td>\n",
       "      <td>That's a long lease.</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.949548</td>\n",
       "      <td>4.751197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well put a fuckin' coat on , son .</td>\n",
       "      <td>well put a coat on , son .</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.908814</td>\n",
       "      <td>6.313572</td>\n",
       "      <td>Well put a coat on, son</td>\n",
       "      <td>0.031059</td>\n",
       "      <td>0.907599</td>\n",
       "      <td>4.444399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and i thought south park was just making shit up .</td>\n",
       "      <td>And I thought Southpark was just making stuff up</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.884786</td>\n",
       "      <td>4.868238</td>\n",
       "      <td>and i thought south park was just making things up.</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.949487</td>\n",
       "      <td>5.096058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>they would have taken out every bad guy holding a gun .</td>\n",
       "      <td>they would have taken out every guy holding a gun</td>\n",
       "      <td>0.249951</td>\n",
       "      <td>0.948061</td>\n",
       "      <td>4.473475</td>\n",
       "      <td>they would have taken out every bad guy holding a gun.</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.101088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>holy fuck , do those kids need gold - lined sneakers or something ?</td>\n",
       "      <td>Do these kids need gold-lined sneakers or something?</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.942673</td>\n",
       "      <td>5.061999</td>\n",
       "      <td>Do those kids need gold-lined sneakers or something?</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.944684</td>\n",
       "      <td>5.017157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sick and tired of the laughable or poisonous stuff promoted by these religious psychos and attributing it to mary .</td>\n",
       "      <td>I get uncomfortable with this and they attribute it to Mary, like it isn't bad</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.564850</td>\n",
       "      <td>4.708082</td>\n",
       "      <td>sick and tired of the jokeable stuff promoted by these religious people and attributing it to mary.</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>0.883124</td>\n",
       "      <td>5.127156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>its like telling your girl friend shes fat then asking her to marry you .</td>\n",
       "      <td>It's like being disrespectful to your girlfrind and then asking her to marry you.</td>\n",
       "      <td>0.090128</td>\n",
       "      <td>0.662332</td>\n",
       "      <td>3.709056</td>\n",
       "      <td>It's like telling your friend she's fat then asking her to marry you.</td>\n",
       "      <td>0.805633</td>\n",
       "      <td>0.959673</td>\n",
       "      <td>3.648295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        original_toxic  \\\n",
       "0                                                            you lack of understanding about jack shit means nothing .   \n",
       "1                                                                         - gotta small ass cut & shits bleedin alot -   \n",
       "2                                                                                         omg , stephens is so silly .   \n",
       "3                                                                                           that 's a long ass lease .   \n",
       "4                                                                                   well put a fuckin' coat on , son .   \n",
       "5                                                                   and i thought south park was just making shit up .   \n",
       "6                                                              they would have taken out every bad guy holding a gun .   \n",
       "7                                                  holy fuck , do those kids need gold - lined sneakers or something ?   \n",
       "8  sick and tired of the laughable or poisonous stuff promoted by these religious psychos and attributing it to mary .   \n",
       "9                                            its like telling your girl friend shes fat then asking her to marry you .   \n",
       "\n",
       "                                                                   reference_neutral  \\\n",
       "0                                           you lack of understanding means nothing.   \n",
       "1                                            got a small cut and it’s bleeding a lot   \n",
       "2                                                        omg , stephens is So wrong.   \n",
       "3                                                         That is a very long lease.   \n",
       "4                                                         well put a coat on , son .   \n",
       "5                                   And I thought Southpark was just making stuff up   \n",
       "6                                  they would have taken out every guy holding a gun   \n",
       "7                               Do these kids need gold-lined sneakers or something?   \n",
       "8     I get uncomfortable with this and they attribute it to Mary, like it isn't bad   \n",
       "9  It's like being disrespectful to your girlfrind and then asking her to marry you.   \n",
       "\n",
       "   toxicity_ref  similarity_orig_ref  fluency_ref  \\\n",
       "0      0.174015             0.805867     5.515510   \n",
       "1      0.026665             0.767247     5.725555   \n",
       "2      0.000803             0.838825     7.768141   \n",
       "3      0.000652             0.931736     4.248515   \n",
       "4      0.020700             0.908814     6.313572   \n",
       "5      0.000652             0.884786     4.868238   \n",
       "6      0.249951             0.948061     4.473475   \n",
       "7      0.001271             0.942673     5.061999   \n",
       "8      0.000803             0.564850     4.708082   \n",
       "9      0.090128             0.662332     3.709056   \n",
       "\n",
       "                                                                                     generated_neutral  \\\n",
       "0                                                   You lack of understanding about this means nothing   \n",
       "1                                                                     - gotta small cut & bleed alot -   \n",
       "2                                                                           omg, stephens is so silly.   \n",
       "3                                                                                 That's a long lease.   \n",
       "4                                                                              Well put a coat on, son   \n",
       "5                                                  and i thought south park was just making things up.   \n",
       "6                                               they would have taken out every bad guy holding a gun.   \n",
       "7                                                 Do those kids need gold-lined sneakers or something?   \n",
       "8  sick and tired of the jokeable stuff promoted by these religious people and attributing it to mary.   \n",
       "9                                It's like telling your friend she's fat then asking her to marry you.   \n",
       "\n",
       "   toxicity_gen  similarity_orig_gen  fluency_gen  \n",
       "0      0.028095             0.787423     5.443557  \n",
       "1      0.527137             0.925930     8.395499  \n",
       "2      0.443403             1.000000     5.921991  \n",
       "3      0.000772             0.949548     4.751197  \n",
       "4      0.031059             0.907599     4.444399  \n",
       "5      0.000635             0.949487     5.096058  \n",
       "6      0.168187             1.000000     4.101088  \n",
       "7      0.001151             0.944684     5.017157  \n",
       "8      0.080387             0.883124     5.127156  \n",
       "9      0.805633             0.959673     3.648295  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -- coding: utf-8 --\n",
    "\n",
    "\"\"\"\n",
    "test_detoxification.py\n",
    "\n",
    "Loads a fine-tuned T5 detoxification model, samples from the evaluation split,\n",
    "generates detoxified outputs, scores toxicity, semantic similarity, and fluency\n",
    "for both the reference neutral sentences and the model’s generated sentences,\n",
    "and displays the results in a pandas DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from data_processing import load_dataset_from_disk\n",
    "\n",
    "# ── Display settings ────────────────────────────────────────────────────────\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────\n",
    "cfg = yaml.safe_load(open(\"main_config.yml\", \"r\"))\n",
    "output_dir = cfg[\"sft_params\"][\"output_dir\"].rstrip(\"/\") + \"/checkpoint-6800\"\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ── Load fine-tuned model & tokenizer ───────────────────────────────────────\n",
    "print(f\"Loading model from {output_dir}...\")\n",
    "model     = T5ForConditionalGeneration.from_pretrained(output_dir).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\")\n",
    "\n",
    "# ── Load & sample evaluation split ──────────────────────────────────────────\n",
    "print(\"Loading and sampling evaluation dataset...\")\n",
    "eval_ds  = load_dataset_from_disk(\"eval_dataset\")\n",
    "n_trials = 10\n",
    "sampled  = eval_ds.shuffle(seed=42).select(range(n_trials))\n",
    "\n",
    "# ── Generate detoxified outputs ─────────────────────────────────────────────\n",
    "print(\"Generating detoxified sentences...\")\n",
    "results = []\n",
    "for ex in sampled:\n",
    "    orig = ex[\"toxic\"]\n",
    "    ref  = ex[\"neutral\"]\n",
    "    inp  = f\"detoxify: {orig}\"\n",
    "\n",
    "    enc = tokenizer(inp, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    out_ids = model.generate(\n",
    "        input_ids=enc.input_ids,\n",
    "        attention_mask=enc.attention_mask,\n",
    "        max_length=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    gen = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    results.append({\n",
    "        \"original_toxic\":    orig,\n",
    "        \"reference_neutral\": ref,\n",
    "        \"generated_neutral\": gen\n",
    "    })\n",
    "\n",
    "# ── Setup toxicity model ────────────────────────────────────────────────────\n",
    "print(\"Loading toxicity model...\")\n",
    "tox_tok = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
    "tox_mod = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"unitary/toxic-bert\"\n",
    ").to(device).eval()\n",
    "label2id = tox_mod.config.label2id\n",
    "tox_label = label2id.get(\"toxicity\", list(label2id.values())[0])\n",
    "\n",
    "# ── Setup similarity model ──────────────────────────────────────────────────\n",
    "print(\"Loading similarity model...\")\n",
    "sim_tok = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "sim_mod = AutoModel.from_pretrained(\n",
    "    \"princeton-nlp/sup-simcse-bert-base-uncased\"\n",
    ").to(device).eval()\n",
    "\n",
    "# ── Score toxicity ──────────────────────────────────────────────────────────\n",
    "print(\"Scoring toxicity...\")\n",
    "tox_inputs = tox_tok(\n",
    "    [r[\"original_toxic\"] for r in results] +\n",
    "    [r[\"reference_neutral\"] for r in results] +\n",
    "    [r[\"generated_neutral\"] for r in results],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    tox_logits = tox_mod(**tox_inputs).logits\n",
    "    tox_probs  = torch.sigmoid(tox_logits)\n",
    "\n",
    "n = len(results)\n",
    "orig_tox = tox_probs[:n,    tox_label].cpu().numpy()\n",
    "ref_tox  = tox_probs[n:2*n, tox_label].cpu().numpy()\n",
    "gen_tox  = tox_probs[2*n: , tox_label].cpu().numpy()\n",
    "\n",
    "# ── Compute semantic similarity ──────────────────────────────────────────────\n",
    "print(\"Computing semantic similarity...\")\n",
    "sim_inputs = sim_tok(\n",
    "    [r[\"original_toxic\"] for r in results] +\n",
    "    [r[\"reference_neutral\"] for r in results] +\n",
    "    [r[\"generated_neutral\"] for r in results],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb_all = sim_mod(**sim_inputs, return_dict=True).pooler_output\n",
    "\n",
    "emb_orig = emb_all[:n]\n",
    "emb_ref  = emb_all[n:2*n]\n",
    "emb_gen  = emb_all[2*n:3*n]\n",
    "\n",
    "sim_orig_ref = F.cosine_similarity(emb_orig, emb_ref, dim=1).cpu().numpy()\n",
    "sim_orig_gen = F.cosine_similarity(emb_orig, emb_gen, dim=1).cpu().numpy()\n",
    "\n",
    "# ── Compute fluency (LM loss) ───────────────────────────────────────────────\n",
    "print(\"Computing fluency loss with GPT-2...\")\n",
    "lm_tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# Ensure pad_token is defined for GPT-2 tokenizer\n",
    "if lm_tok.pad_token is None:\n",
    "    lm_tok.pad_token = lm_tok.eos_token\n",
    "    lm_tok.pad_token_id = lm_tok.eos_token_id\n",
    "lm_mod = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device).eval()\n",
    "\n",
    "fluency_ref = []\n",
    "fluency_gen = []\n",
    "for ref, gen in zip([r[\"reference_neutral\"] for r in results],\n",
    "                     [r[\"generated_neutral\"] for r in results]):\n",
    "    # reference\n",
    "    enc_ref = lm_tok(ref, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        loss_ref = lm_mod(**enc_ref, labels=enc_ref[\"input_ids\"]).loss.item()\n",
    "    fluency_ref.append(loss_ref)\n",
    "    # generated\n",
    "    enc_gen = lm_tok(gen, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        loss_gen = lm_mod(**enc_gen, labels=enc_gen[\"input_ids\"]).loss.item()\n",
    "    fluency_gen.append(loss_gen)\n",
    "\n",
    "# ── Attach scores and build DataFrame ───────────────────────────────────────\n",
    "for i, r in enumerate(results):\n",
    "    r[\"toxicity_ref\"]        = float(ref_tox[i])\n",
    "    r[\"similarity_orig_ref\"] = float(sim_orig_ref[i])\n",
    "    r[\"toxicity_gen\"]        = float(gen_tox[i])\n",
    "    r[\"similarity_orig_gen\"] = float(sim_orig_gen[i])\n",
    "    r[\"fluency_ref\"]         = float(fluency_ref[i])\n",
    "    r[\"fluency_gen\"]         = float(fluency_gen[i])\n",
    "\n",
    "# ── Display results ─────────────────────────────────────────────────────────\n",
    "df = pd.DataFrame(results)[[\n",
    "    \"original_toxic\",\n",
    "    \"reference_neutral\",\n",
    "    \"toxicity_ref\",\n",
    "    \"similarity_orig_ref\",\n",
    "    \"fluency_ref\",\n",
    "    \"generated_neutral\",\n",
    "    \"toxicity_gen\",\n",
    "    \"similarity_orig_gen\",\n",
    "    \"fluency_gen\"\n",
    "]]\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e22e726",
   "metadata": {},
   "source": [
    "### COUNT Trial ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3e1cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "🔴 Toxic Input:\n",
      "i love you so fucking much baby\n",
      "📊 MLE: 1.1604, UL: 4.1501, Toxicity: 0.9574, Total: 3.6127\n",
      "\n",
      "🟢 Detoxified Output:\n",
      "I love you so much baby\n",
      "📊 MLE: 0.0650, UL: 4.0288, Toxicity: 0.0009, Total: 2.0479\n",
      "\n",
      "✅ Ground Truth:\n",
      "i love you so much baby\n",
      "📊 MLE: 0.2338, UL: 5.1951, Toxicity: 0.0009, Total: 2.7154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    ")\n",
    "\n",
    "# === Setup ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model_path = \"outputs/COUNT/count_e20\"\n",
    "model_path = \"outputs/COUNT/checkpoint-6900\"\n",
    "tox_model_name = \"unitary/toxic-bert\"\n",
    "\n",
    "# === Load models ===\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(device).eval()\n",
    "tox_tokenizer = AutoTokenizer.from_pretrained(tox_model_name)\n",
    "tox_model = AutoModelForSequenceClassification.from_pretrained(tox_model_name).to(device).eval()\n",
    "\n",
    "# === Load test data ===\n",
    "test_data = load_from_disk(\"cleaned_data/test_dataset\")\n",
    "\n",
    "# === Toxicity function ===\n",
    "def get_toxicity_score(text):\n",
    "    inputs = tox_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = tox_model(**inputs).logits\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return float(probs[0][0])\n",
    "\n",
    "# === Loss function ===\n",
    "def compute_losses(input_text, target_text):\n",
    "    # Encode input (e.g., \"detoxify: ...\")\n",
    "    input_enc = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=64)\n",
    "    input_enc = {k: v.to(device) for k, v in input_enc.items()}\n",
    "\n",
    "    # Encode target (e.g., neutral sentence)\n",
    "    target_enc = tokenizer(target_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=64)\n",
    "    labels = target_enc[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_enc, labels=labels)\n",
    "        mle_loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Unlikelihood loss\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        neg_log_probs = torch.log(1.0 - probs + 1e-6)\n",
    "        safe_labels = labels.clone()\n",
    "        safe_labels[safe_labels == -100] = 0\n",
    "        ul_loss = -neg_log_probs.gather(-1, safe_labels.unsqueeze(-1)).squeeze(-1)\n",
    "        pad_mask = labels != -100\n",
    "        ul_loss = (ul_loss * pad_mask).sum() / pad_mask.sum()\n",
    "\n",
    "        # Toxicity penalty (on target_text)\n",
    "        tox_score = get_toxicity_score(target_text)\n",
    "\n",
    "    return mle_loss.item(), ul_loss.item(), tox_score\n",
    "\n",
    "# === Select random samples ===\n",
    "sample_indices = random.sample(range(len(test_data)), 3)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    example = test_data[idx]\n",
    "    toxic_input = example[\"toxic\"]\n",
    "    ground_truth = example[\"neutral\"]\n",
    "    input_text = \"detoxify: \" + toxic_input\n",
    "\n",
    "    # Generate detoxified output\n",
    "    input_enc = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=64)\n",
    "    input_enc = {k: v.to(device) for k, v in input_enc.items()}\n",
    "    with torch.no_grad():\n",
    "        gen_ids = model.generate(**input_enc, max_length=64, num_beams=4)\n",
    "        detoxified_output = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # === Compute all losses ===\n",
    "    losses_input     = compute_losses(input_text, toxic_input)\n",
    "    losses_output    = compute_losses(input_text, detoxified_output)\n",
    "    losses_target    = compute_losses(input_text, ground_truth)\n",
    "\n",
    "# === Combine losses using training weights ===\n",
    "mle_w = 0.5\n",
    "ul_w = 0.5\n",
    "tox_w = 1.0\n",
    "\n",
    "def combine(mle, ul, tox):\n",
    "    return mle_w * mle + ul_w * ul + tox_w * tox\n",
    "\n",
    "score_input = combine(*losses_input)\n",
    "score_output = combine(*losses_output)\n",
    "score_target = combine(*losses_target)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(f\"🔴 Toxic Input:\\n{toxic_input}\")\n",
    "print(f\"📊 MLE: {losses_input[0]:.4f}, UL: {losses_input[1]:.4f}, Toxicity: {losses_input[2]:.4f}, Total: {score_input:.4f}\")\n",
    "print()\n",
    "print(f\"🟢 Detoxified Output:\\n{detoxified_output}\")\n",
    "print(f\"📊 MLE: {losses_output[0]:.4f}, UL: {losses_output[1]:.4f}, Toxicity: {losses_output[2]:.4f}, Total: {score_output:.4f}\")\n",
    "print()\n",
    "print(f\"✅ Ground Truth:\\n{ground_truth}\")\n",
    "print(f\"📊 MLE: {losses_target[0]:.4f}, UL: {losses_target[1]:.4f}, Toxicity: {losses_target[2]:.4f}, Total: {score_target:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736f9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ee7fecf0a62caab1efc8b48ca7a865bcfb68930a7ec34d991525f61183930d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
